{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eUduHdRzRl3b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kXHfhmj5Sg8I"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# set -m\n",
        "# git clone https://github.com/sachdevkartik/DeepLense.git\n",
        "# cd DeepLense && git checkout kartik_contribution\n",
        "# cd ..\n",
        "# mv DeepLense/Transformers_Classification_DeepLense_Kartik_Sachdev/* .\n",
        "# rm -rf DeepLense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GO-o2tDFTzRi"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c1HY0pEaLFG",
        "outputId": "faafc9b6-dc46-4152-9980-5117273aec44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jul 30 15:35:04 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    31W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v5bBZlqLTw7f"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# pip3 install --upgrade -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p4PjBZQfY5oH"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dBA_SAO_Y6rq"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FLbLTB7NT-Iq"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import json\n",
        "import yaml\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "import torchvision\n",
        "from typing import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RtAGUsIfUCxM"
      },
      "outputs": [],
      "source": [
        "from utils.util import *\n",
        "from utils.inference import InferenceSSL\n",
        "from argparse import ArgumentParser\n",
        "from config.data_config import DATASET\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from models.cnn_zoo import CustomResNet\n",
        "from models.byol import BYOL, BYOLSingleChannel\n",
        "\n",
        "\n",
        "from utils.dataset import DefaultDatasetSetupSSL\n",
        "from self_supervised.losses.contrastive_loss import (\n",
        "    ContrastiveLossEuclidean,\n",
        "    ContrastiveLossEmbedding,\n",
        "    SimCLR_Loss,\n",
        "    NegativeCosineSimilarity,\n",
        ")\n",
        "from utils.train import (\n",
        "    train_simplistic,\n",
        "    train_byol,\n",
        "    train_contrastive_pair,\n",
        "    train_contrastive_with_labels,\n",
        "    train_contrastive,\n",
        ")\n",
        "from self_supervised.losses.sym_neg_cos_sim_loss import SymNegCosineSimilarityLoss\n",
        "\n",
        "from models.modules.head import BYOLProjectionHead, BYOLPredictionHead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FBe_PZNHUDdG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-8do6lzzUD4j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Rd3Ra8x_XG5D"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    \"dataset_name\": \"Model_II\",\n",
        "    \"save\": \"/content/drive/MyDrive/deeplense/data\",\n",
        "    \"num_workers\": 8,\n",
        "    \"train_config_path\": \"self_supervised/config/resnet_byol.yaml\",\n",
        "    \"cuda\": True,\n",
        "    \"log_dir\": \"logger\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "e_BlwV27XHye"
      },
      "outputs": [],
      "source": [
        "dataset_name = args[\"dataset_name\"]\n",
        "dataset_dir = args[\"save\"]\n",
        "use_cuda = args[\"cuda\"]\n",
        "num_workers = args[\"num_workers\"]\n",
        "train_config_path = args[\"train_config_path\"]\n",
        "log_dir_base = args[\"log_dir\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "r3neGI8FXH6S"
      },
      "outputs": [],
      "source": [
        "classes = DATASET[f\"{dataset_name}\"][\"classes\"]\n",
        "num_classes = len(classes)\n",
        "\n",
        "# Open the YAML file and load its contents\n",
        "with open(train_config_path, \"r\") as file:\n",
        "    train_config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Fk2BrahLXIQg"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs_pretrained = train_config[\"pretrained\"][\"num_epochs\"]\n",
        "epochs_finetuned = train_config[\"finetuned\"][\"num_epochs\"]\n",
        "\n",
        "learning_rate = train_config[\"optimizer_config\"][\"lr\"]\n",
        "margin = train_config[\"ssl\"][\"margin\"]\n",
        "num_channels = train_config[\"channels\"]\n",
        "temperature = train_config[\"ssl\"][\"temperature\"]\n",
        "network_type = train_config[\"network_type\"]\n",
        "image_size = train_config[\"image_size\"]\n",
        "optimizer_config = train_config[\"optimizer_config\"]\n",
        "\n",
        "backbone = train_config[\"backbone\"]\n",
        "\n",
        "make_directories([dataset_dir])\n",
        "seed_everything(seed=42)\n",
        "\n",
        "# logging\n",
        "current_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
        "log_dir = f\"{log_dir_base}/{current_time}\"\n",
        "init_logging_handler(log_dir_base, current_time)\n",
        "\n",
        "# dump config in logger\n",
        "with open(f\"{log_dir}/config.json\", \"w\") as fp:\n",
        "    json.dump(train_config, fp)\n",
        "\n",
        "# saving model path location\n",
        "model_path_pretrained = os.path.join(\n",
        "    f\"{log_dir}/checkpoint\",\n",
        "    f\"{network_type}_pretrained_{dataset_name}_{current_time}.pt\",\n",
        ")\n",
        "\n",
        "model_path_finetune = os.path.join(\n",
        "    f\"{log_dir}/checkpoint\",\n",
        "    f\"{network_type}_finetune_{dataset_name}_{current_time}.pt\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjU0UUKVXIiA",
        "outputId": "9abb6f3f-bc71-4bf3-8426-1e0fb0db15fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Multiple Transforms\n",
            ">>> Multiple Transforms\n"
          ]
        }
      ],
      "source": [
        "# setup default dataset\n",
        "default_dataset_setup = DefaultDatasetSetupSSL()\n",
        "default_dataset_setup.setup(dataset_name=dataset_name)\n",
        "default_dataset_setup.setup_transforms(image_size=image_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zLBymamXIx5",
        "outputId": "55e7933c-730f-4f97-c206-3905378761b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model_II dataset already exists\n",
            "train data: 89104\n"
          ]
        }
      ],
      "source": [
        "# trainset\n",
        "train_dataset = default_dataset_setup.get_dataset(mode=\"train\")\n",
        "# default_dataset_setup.visualize_dataset(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxquTvHKUEN_",
        "outputId": "57116f52-9433-4ba5-dddb-e24585bacdeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of classes:  3\n",
            "torch.Size([64, 1, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# split in train and valid set\n",
        "split_ratio = 0.25  # 0.25\n",
        "valid_len = int(split_ratio * len(train_dataset))\n",
        "train_len = len(train_dataset) - valid_len\n",
        "\n",
        "train_dataset, val_set = random_split(train_dataset, [train_len, valid_len])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_set, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        ")\n",
        "\n",
        "# Load test dataset\n",
        "# testset = default_dataset_setup.get_dataset(mode=\"val\")\n",
        "# test_loader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# size check\n",
        "sample = next(iter(train_loader))\n",
        "print(\"num of classes: \", num_classes)\n",
        "print(sample[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUdzIhd3YZyQ",
        "outputId": "60a4dd4d-1152-4f4a-ba9f-e332eacfc8b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/self_supervised/losses/sym_neg_cos_sim_loss.py:35: Warning: SymNegCosineSimiliarityLoss will be deprecated in favor of NegativeCosineSimilarity in the future.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Create pretrain model\n",
        "resnet = torchvision.models.resnet50()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "model = BYOLSingleChannel(backbone, num_ftrs=2048)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "# summary(model, input_size=(1, 1, 224, 224), device=\"cuda\")\n",
        "\n",
        "########################## Pretraining #############################\n",
        "\n",
        "# optimizer and loss function for pretrain\n",
        "optimizer_pretrain = torch.optim.SGD(model.parameters(), lr=0.06)\n",
        "\n",
        "# criterion\n",
        "# criterion_pretrain = NegativeCosineSimilarity()s\n",
        "criterion_pretrain = SymNegCosineSimilarityLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuBQdozRYcvp",
        "outputId": "001cdcf9-996d-46d8-9a93-6d3888a3d603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0/10], Batch [0/1045], Loss: -0.0018986132927238941\n",
            "Epoch [0/10], Batch [10/1045], Loss: -0.6732980012893677\n",
            "Epoch [0/10], Batch [20/1045], Loss: -0.762669563293457\n",
            "Epoch [0/10], Batch [30/1045], Loss: -0.8373775482177734\n",
            "Epoch [0/10], Batch [40/1045], Loss: -0.8390130996704102\n",
            "Epoch [0/10], Batch [50/1045], Loss: -0.9137295484542847\n",
            "Epoch [0/10], Batch [60/1045], Loss: -0.9012939929962158\n",
            "Epoch [0/10], Batch [70/1045], Loss: -0.9290071725845337\n",
            "Epoch [0/10], Batch [80/1045], Loss: -0.8955908417701721\n",
            "Epoch [0/10], Batch [90/1045], Loss: -0.9026325941085815\n",
            "Epoch [0/10], Batch [100/1045], Loss: -0.9176199436187744\n",
            "Epoch [0/10], Batch [110/1045], Loss: -0.9116210341453552\n",
            "Epoch [0/10], Batch [120/1045], Loss: -0.9298646450042725\n",
            "Epoch [0/10], Batch [130/1045], Loss: -0.9056341648101807\n",
            "Epoch [0/10], Batch [140/1045], Loss: -0.9072104096412659\n",
            "Epoch [0/10], Batch [150/1045], Loss: -0.9612534046173096\n",
            "Epoch [0/10], Batch [160/1045], Loss: -0.93021160364151\n",
            "Epoch [0/10], Batch [170/1045], Loss: -0.9193705320358276\n",
            "Epoch [0/10], Batch [180/1045], Loss: -0.9287620782852173\n",
            "Epoch [0/10], Batch [190/1045], Loss: -0.953992486000061\n",
            "Epoch [0/10], Batch [200/1045], Loss: -0.95531165599823\n",
            "Epoch [0/10], Batch [210/1045], Loss: -0.968432605266571\n",
            "Epoch [0/10], Batch [220/1045], Loss: -0.9232579469680786\n",
            "Epoch [0/10], Batch [230/1045], Loss: -0.9655634164810181\n",
            "Epoch [0/10], Batch [240/1045], Loss: -0.956646203994751\n",
            "Epoch [0/10], Batch [250/1045], Loss: -0.9529813528060913\n",
            "Epoch [0/10], Batch [260/1045], Loss: -0.9341116547584534\n",
            "Epoch [0/10], Batch [270/1045], Loss: -0.9195844531059265\n",
            "Epoch [0/10], Batch [280/1045], Loss: -0.9722397327423096\n",
            "Epoch [0/10], Batch [290/1045], Loss: -0.9593678116798401\n",
            "Epoch [0/10], Batch [300/1045], Loss: -0.94808030128479\n",
            "Epoch [0/10], Batch [310/1045], Loss: -0.9593037366867065\n",
            "Epoch [0/10], Batch [320/1045], Loss: -0.9584652781486511\n",
            "Epoch [0/10], Batch [330/1045], Loss: -0.9648959636688232\n",
            "Epoch [0/10], Batch [340/1045], Loss: -0.9627612233161926\n",
            "Epoch [0/10], Batch [350/1045], Loss: -0.9729694128036499\n",
            "Epoch [0/10], Batch [360/1045], Loss: -0.971184253692627\n",
            "Epoch [0/10], Batch [370/1045], Loss: -0.9609102606773376\n",
            "Epoch [0/10], Batch [380/1045], Loss: -0.9699352979660034\n",
            "Epoch [0/10], Batch [390/1045], Loss: -0.9832719564437866\n",
            "Epoch [0/10], Batch [400/1045], Loss: -0.9833125472068787\n",
            "Epoch [0/10], Batch [410/1045], Loss: -0.960029661655426\n",
            "Epoch [0/10], Batch [420/1045], Loss: -0.9696916341781616\n",
            "Epoch [0/10], Batch [430/1045], Loss: -0.9453129172325134\n",
            "Epoch [0/10], Batch [440/1045], Loss: -0.9610183238983154\n",
            "Epoch [0/10], Batch [450/1045], Loss: -0.9695887565612793\n",
            "Epoch [0/10], Batch [460/1045], Loss: -0.9645638465881348\n",
            "Epoch [0/10], Batch [470/1045], Loss: -0.9577728509902954\n",
            "Epoch [0/10], Batch [480/1045], Loss: -0.9758931398391724\n",
            "Epoch [0/10], Batch [490/1045], Loss: -0.9680805206298828\n",
            "Epoch [0/10], Batch [500/1045], Loss: -0.9827877283096313\n",
            "Epoch [0/10], Batch [510/1045], Loss: -0.9633381366729736\n",
            "Epoch [0/10], Batch [520/1045], Loss: -0.9705119132995605\n",
            "Epoch [0/10], Batch [530/1045], Loss: -0.9723014831542969\n",
            "Epoch [0/10], Batch [540/1045], Loss: -0.9897448420524597\n",
            "Epoch [0/10], Batch [550/1045], Loss: -0.9654187560081482\n",
            "Epoch [0/10], Batch [560/1045], Loss: -0.9671311974525452\n",
            "Epoch [0/10], Batch [570/1045], Loss: -0.9856594204902649\n",
            "Epoch [0/10], Batch [580/1045], Loss: -0.9803551435470581\n",
            "Epoch [0/10], Batch [590/1045], Loss: -0.9685834646224976\n",
            "Epoch [0/10], Batch [600/1045], Loss: -0.9722083210945129\n",
            "Epoch [0/10], Batch [610/1045], Loss: -0.9888128638267517\n",
            "Epoch [0/10], Batch [620/1045], Loss: -0.9542443752288818\n",
            "Epoch [0/10], Batch [630/1045], Loss: -0.9802846908569336\n",
            "Epoch [0/10], Batch [640/1045], Loss: -0.9594921469688416\n",
            "Epoch [0/10], Batch [650/1045], Loss: -0.9643213748931885\n",
            "Epoch [0/10], Batch [660/1045], Loss: -0.979968786239624\n",
            "Epoch [0/10], Batch [670/1045], Loss: -0.9828128814697266\n",
            "Epoch [0/10], Batch [680/1045], Loss: -0.9741874933242798\n",
            "Epoch [0/10], Batch [690/1045], Loss: -0.9739398956298828\n",
            "Epoch [0/10], Batch [700/1045], Loss: -0.9806199073791504\n",
            "Epoch [0/10], Batch [710/1045], Loss: -0.9664549231529236\n",
            "Epoch [0/10], Batch [720/1045], Loss: -0.9854401350021362\n",
            "Epoch [0/10], Batch [730/1045], Loss: -0.9871687889099121\n",
            "Epoch [0/10], Batch [740/1045], Loss: -0.9880692958831787\n",
            "Epoch [0/10], Batch [750/1045], Loss: -0.9829515814781189\n",
            "Epoch [0/10], Batch [760/1045], Loss: -0.9841678142547607\n",
            "Epoch [0/10], Batch [770/1045], Loss: -0.9896394610404968\n",
            "Epoch [0/10], Batch [780/1045], Loss: -0.986032247543335\n",
            "Epoch [0/10], Batch [790/1045], Loss: -0.9802384376525879\n",
            "Epoch [0/10], Batch [800/1045], Loss: -0.9886155724525452\n",
            "Epoch [0/10], Batch [810/1045], Loss: -0.9799200296401978\n",
            "Epoch [0/10], Batch [820/1045], Loss: -0.963679850101471\n",
            "Epoch [0/10], Batch [830/1045], Loss: -0.9881081581115723\n",
            "Epoch [0/10], Batch [840/1045], Loss: -0.9842489361763\n",
            "Epoch [0/10], Batch [850/1045], Loss: -0.9842041730880737\n",
            "Epoch [0/10], Batch [860/1045], Loss: -0.987033486366272\n",
            "Epoch [0/10], Batch [870/1045], Loss: -0.989738941192627\n",
            "Epoch [0/10], Batch [880/1045], Loss: -0.9843426942825317\n",
            "Epoch [0/10], Batch [890/1045], Loss: -0.991597592830658\n",
            "Epoch [0/10], Batch [900/1045], Loss: -0.9895532131195068\n",
            "Epoch [0/10], Batch [910/1045], Loss: -0.9879657626152039\n",
            "Epoch [0/10], Batch [920/1045], Loss: -0.9885843992233276\n",
            "Epoch [0/10], Batch [930/1045], Loss: -0.9909782409667969\n",
            "Epoch [0/10], Batch [940/1045], Loss: -0.9857425093650818\n",
            "Epoch [0/10], Batch [950/1045], Loss: -0.9819972515106201\n",
            "Epoch [0/10], Batch [960/1045], Loss: -0.9562802314758301\n",
            "Epoch [0/10], Batch [970/1045], Loss: -0.9688812494277954\n",
            "Epoch [0/10], Batch [980/1045], Loss: -0.9926801919937134\n",
            "Epoch [0/10], Batch [990/1045], Loss: -0.9850647449493408\n",
            "Epoch [0/10], Batch [1000/1045], Loss: -0.984627902507782\n",
            "Epoch [0/10], Batch [1010/1045], Loss: -0.9833218455314636\n",
            "Epoch [0/10], Batch [1020/1045], Loss: -0.9890246391296387\n",
            "Epoch [0/10], Batch [1030/1045], Loss: -0.982817530632019\n",
            "Epoch [0/10], Batch [1040/1045], Loss: -0.990047037601471\n",
            ">>>>> Epoch: 00, Epoch Loss: -0.95492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Batch [0/1045], Loss: -0.9911845326423645\n",
            "Epoch [1/10], Batch [10/1045], Loss: -0.9897962808609009\n",
            "Epoch [1/10], Batch [20/1045], Loss: -0.985688328742981\n",
            "Epoch [1/10], Batch [30/1045], Loss: -0.9864813089370728\n",
            "Epoch [1/10], Batch [40/1045], Loss: -0.993876576423645\n",
            "Epoch [1/10], Batch [50/1045], Loss: -0.9837156534194946\n",
            "Epoch [1/10], Batch [60/1045], Loss: -0.9895741939544678\n",
            "Epoch [1/10], Batch [70/1045], Loss: -0.9922720193862915\n",
            "Epoch [1/10], Batch [80/1045], Loss: -0.9791045784950256\n",
            "Epoch [1/10], Batch [90/1045], Loss: -0.9841586947441101\n",
            "Epoch [1/10], Batch [100/1045], Loss: -0.9893655776977539\n",
            "Epoch [1/10], Batch [110/1045], Loss: -0.9841111898422241\n",
            "Epoch [1/10], Batch [120/1045], Loss: -0.990739107131958\n",
            "Epoch [1/10], Batch [130/1045], Loss: -0.9912154078483582\n",
            "Epoch [1/10], Batch [140/1045], Loss: -0.9903329014778137\n",
            "Epoch [1/10], Batch [150/1045], Loss: -0.9941809773445129\n",
            "Epoch [1/10], Batch [160/1045], Loss: -0.9908374547958374\n",
            "Epoch [1/10], Batch [170/1045], Loss: -0.9859068393707275\n",
            "Epoch [1/10], Batch [180/1045], Loss: -0.9742511510848999\n",
            "Epoch [1/10], Batch [190/1045], Loss: -0.9902803897857666\n",
            "Epoch [1/10], Batch [200/1045], Loss: -0.9922529458999634\n",
            "Epoch [1/10], Batch [210/1045], Loss: -0.9765353202819824\n",
            "Epoch [1/10], Batch [220/1045], Loss: -0.987821638584137\n",
            "Epoch [1/10], Batch [230/1045], Loss: -0.9827032685279846\n",
            "Epoch [1/10], Batch [240/1045], Loss: -0.9796477556228638\n",
            "Epoch [1/10], Batch [250/1045], Loss: -0.9922077655792236\n",
            "Epoch [1/10], Batch [260/1045], Loss: -0.9830078482627869\n",
            "Epoch [1/10], Batch [270/1045], Loss: -0.9922680854797363\n",
            "Epoch [1/10], Batch [280/1045], Loss: -0.9872767925262451\n",
            "Epoch [1/10], Batch [290/1045], Loss: -0.9924829006195068\n",
            "Epoch [1/10], Batch [300/1045], Loss: -0.9944213032722473\n",
            "Epoch [1/10], Batch [310/1045], Loss: -0.9833866953849792\n",
            "Epoch [1/10], Batch [320/1045], Loss: -0.9905162453651428\n",
            "Epoch [1/10], Batch [330/1045], Loss: -0.9904619455337524\n",
            "Epoch [1/10], Batch [340/1045], Loss: -0.991259753704071\n",
            "Epoch [1/10], Batch [350/1045], Loss: -0.9680358171463013\n",
            "Epoch [1/10], Batch [360/1045], Loss: -0.9939069747924805\n",
            "Epoch [1/10], Batch [370/1045], Loss: -0.9940398931503296\n",
            "Epoch [1/10], Batch [380/1045], Loss: -0.9896144866943359\n",
            "Epoch [1/10], Batch [390/1045], Loss: -0.9824000597000122\n",
            "Epoch [1/10], Batch [400/1045], Loss: -0.991326093673706\n",
            "Epoch [1/10], Batch [410/1045], Loss: -0.990096926689148\n",
            "Epoch [1/10], Batch [420/1045], Loss: -0.9727261662483215\n",
            "Epoch [1/10], Batch [430/1045], Loss: -0.9930149912834167\n",
            "Epoch [1/10], Batch [440/1045], Loss: -0.985932469367981\n",
            "Epoch [1/10], Batch [450/1045], Loss: -0.9822338819503784\n",
            "Epoch [1/10], Batch [460/1045], Loss: -0.9888554811477661\n",
            "Epoch [1/10], Batch [470/1045], Loss: -0.9877322912216187\n",
            "Epoch [1/10], Batch [480/1045], Loss: -0.9930853843688965\n",
            "Epoch [1/10], Batch [490/1045], Loss: -0.9882967472076416\n",
            "Epoch [1/10], Batch [500/1045], Loss: -0.990562915802002\n",
            "Epoch [1/10], Batch [510/1045], Loss: -0.9924946427345276\n",
            "Epoch [1/10], Batch [520/1045], Loss: -0.9936648607254028\n",
            "Epoch [1/10], Batch [530/1045], Loss: -0.993319034576416\n",
            "Epoch [1/10], Batch [540/1045], Loss: -0.9898578524589539\n",
            "Epoch [1/10], Batch [550/1045], Loss: -0.9920521974563599\n",
            "Epoch [1/10], Batch [560/1045], Loss: -0.9893463253974915\n",
            "Epoch [1/10], Batch [570/1045], Loss: -0.9875087738037109\n",
            "Epoch [1/10], Batch [580/1045], Loss: -0.9901264309883118\n",
            "Epoch [1/10], Batch [590/1045], Loss: -0.9936908483505249\n",
            "Epoch [1/10], Batch [600/1045], Loss: -0.9888328909873962\n",
            "Epoch [1/10], Batch [610/1045], Loss: -0.993276834487915\n",
            "Epoch [1/10], Batch [620/1045], Loss: -0.9858695268630981\n",
            "Epoch [1/10], Batch [630/1045], Loss: -0.995874285697937\n",
            "Epoch [1/10], Batch [640/1045], Loss: -0.9949008822441101\n",
            "Epoch [1/10], Batch [650/1045], Loss: -0.9858801364898682\n",
            "Epoch [1/10], Batch [660/1045], Loss: -0.9793018698692322\n",
            "Epoch [1/10], Batch [670/1045], Loss: -0.9933841228485107\n",
            "Epoch [1/10], Batch [680/1045], Loss: -0.9862390756607056\n",
            "Epoch [1/10], Batch [690/1045], Loss: -0.9946982264518738\n",
            "Epoch [1/10], Batch [700/1045], Loss: -0.9936939477920532\n",
            "Epoch [1/10], Batch [710/1045], Loss: -0.9966244697570801\n",
            "Epoch [1/10], Batch [720/1045], Loss: -0.9827374219894409\n",
            "Epoch [1/10], Batch [730/1045], Loss: -0.9933460354804993\n",
            "Epoch [1/10], Batch [740/1045], Loss: -0.9933195114135742\n",
            "Epoch [1/10], Batch [750/1045], Loss: -0.9942288398742676\n",
            "Epoch [1/10], Batch [760/1045], Loss: -0.99128258228302\n",
            "Epoch [1/10], Batch [770/1045], Loss: -0.9895766377449036\n",
            "Epoch [1/10], Batch [780/1045], Loss: -0.9949724078178406\n",
            "Epoch [1/10], Batch [790/1045], Loss: -0.9938579797744751\n",
            "Epoch [1/10], Batch [800/1045], Loss: -0.9888086318969727\n",
            "Epoch [1/10], Batch [810/1045], Loss: -0.9845092296600342\n",
            "Epoch [1/10], Batch [820/1045], Loss: -0.9916497468948364\n",
            "Epoch [1/10], Batch [830/1045], Loss: -0.9964166283607483\n",
            "Epoch [1/10], Batch [840/1045], Loss: -0.9912434816360474\n",
            "Epoch [1/10], Batch [850/1045], Loss: -0.9974769353866577\n",
            "Epoch [1/10], Batch [860/1045], Loss: -0.9858464002609253\n",
            "Epoch [1/10], Batch [870/1045], Loss: -0.9880974292755127\n",
            "Epoch [1/10], Batch [880/1045], Loss: -0.9916496276855469\n",
            "Epoch [1/10], Batch [890/1045], Loss: -0.9894939661026001\n",
            "Epoch [1/10], Batch [900/1045], Loss: -0.9906913042068481\n",
            "Epoch [1/10], Batch [910/1045], Loss: -0.9907748699188232\n",
            "Epoch [1/10], Batch [920/1045], Loss: -0.9953920841217041\n",
            "Epoch [1/10], Batch [930/1045], Loss: -0.9935178160667419\n",
            "Epoch [1/10], Batch [940/1045], Loss: -0.9822156429290771\n",
            "Epoch [1/10], Batch [950/1045], Loss: -0.9956963658332825\n",
            "Epoch [1/10], Batch [960/1045], Loss: -0.9888091087341309\n",
            "Epoch [1/10], Batch [970/1045], Loss: -0.9901074767112732\n",
            "Epoch [1/10], Batch [980/1045], Loss: -0.9968769550323486\n",
            "Epoch [1/10], Batch [990/1045], Loss: -0.9936484694480896\n",
            "Epoch [1/10], Batch [1000/1045], Loss: -0.9933943748474121\n",
            "Epoch [1/10], Batch [1010/1045], Loss: -0.9938323497772217\n",
            "Epoch [1/10], Batch [1020/1045], Loss: -0.996703028678894\n",
            "Epoch [1/10], Batch [1030/1045], Loss: -0.9930278062820435\n",
            "Epoch [1/10], Batch [1040/1045], Loss: -0.9920666217803955\n",
            ">>>>> Epoch: 01, Epoch Loss: -0.98917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1523: UserWarning: The image is already gray.\n",
            "  warnings.warn(\"The image is already gray.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Batch [0/1045], Loss: -0.9941126704216003\n",
            "Epoch [2/10], Batch [10/1045], Loss: -0.994738757610321\n",
            "Epoch [2/10], Batch [20/1045], Loss: -0.9937441349029541\n",
            "Epoch [2/10], Batch [30/1045], Loss: -0.9958057403564453\n",
            "Epoch [2/10], Batch [40/1045], Loss: -0.9866570234298706\n",
            "Epoch [2/10], Batch [50/1045], Loss: -0.9929462671279907\n",
            "Epoch [2/10], Batch [60/1045], Loss: -0.988060712814331\n",
            "Epoch [2/10], Batch [70/1045], Loss: -0.9909249544143677\n",
            "Epoch [2/10], Batch [80/1045], Loss: -0.9954149723052979\n",
            "Epoch [2/10], Batch [90/1045], Loss: -0.9913302659988403\n",
            "Epoch [2/10], Batch [100/1045], Loss: -0.9847187995910645\n",
            "Epoch [2/10], Batch [110/1045], Loss: -0.9968182444572449\n",
            "Epoch [2/10], Batch [120/1045], Loss: -0.9829838871955872\n",
            "Epoch [2/10], Batch [130/1045], Loss: -0.9877912998199463\n",
            "Epoch [2/10], Batch [140/1045], Loss: -0.9950253963470459\n",
            "Epoch [2/10], Batch [150/1045], Loss: -0.9944820404052734\n",
            "Epoch [2/10], Batch [160/1045], Loss: -0.9834882020950317\n",
            "Epoch [2/10], Batch [170/1045], Loss: -0.996030867099762\n",
            "Epoch [2/10], Batch [180/1045], Loss: -0.9895615577697754\n",
            "Epoch [2/10], Batch [190/1045], Loss: -0.9889299869537354\n",
            "Epoch [2/10], Batch [200/1045], Loss: -0.9961326122283936\n",
            "Epoch [2/10], Batch [210/1045], Loss: -0.9865529537200928\n",
            "Epoch [2/10], Batch [220/1045], Loss: -0.993804931640625\n",
            "Epoch [2/10], Batch [230/1045], Loss: -0.9856429696083069\n",
            "Epoch [2/10], Batch [240/1045], Loss: -0.997235119342804\n",
            "Epoch [2/10], Batch [250/1045], Loss: -0.9958067536354065\n",
            "Epoch [2/10], Batch [260/1045], Loss: -0.9948941469192505\n",
            "Epoch [2/10], Batch [270/1045], Loss: -0.9900459051132202\n",
            "Epoch [2/10], Batch [280/1045], Loss: -0.9961316585540771\n",
            "Epoch [2/10], Batch [290/1045], Loss: -0.9957983493804932\n",
            "Epoch [2/10], Batch [300/1045], Loss: -0.9923884868621826\n",
            "Epoch [2/10], Batch [310/1045], Loss: -0.9929747581481934\n",
            "Epoch [2/10], Batch [320/1045], Loss: -0.9961869120597839\n",
            "Epoch [2/10], Batch [330/1045], Loss: -0.9871726036071777\n",
            "Epoch [2/10], Batch [340/1045], Loss: -0.9941741228103638\n",
            "Epoch [2/10], Batch [350/1045], Loss: -0.991184651851654\n",
            "Epoch [2/10], Batch [360/1045], Loss: -0.9922105073928833\n",
            "Epoch [2/10], Batch [370/1045], Loss: -0.9947038888931274\n"
          ]
        }
      ],
      "source": [
        "# pretraining\n",
        "train_byol(\n",
        "    epochs=epochs_pretrained,\n",
        "    model=model,\n",
        "    device=device,\n",
        "    train_loader=train_loader,\n",
        "    criterion=criterion_pretrain,\n",
        "    optimizer=optimizer_pretrain,\n",
        "    saved_model_path=model_path_pretrained,\n",
        "    valid_loader=val_loader,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYXa8R2bb_vD"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVWofjN-Sp6f"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
