{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUduHdRzRl3b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXHfhmj5Sg8I"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# set -m\n",
        "# git clone https://github.com/sachdevkartik/DeepLense.git\n",
        "# cd DeepLense && git checkout kartik_contribution\n",
        "# cd ..\n",
        "# mv DeepLense/Transformers_Classification_DeepLense_Kartik_Sachdev/* .\n",
        "# rm -rf DeepLense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO-o2tDFTzRi"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c1HY0pEaLFG",
        "outputId": "faafc9b6-dc46-4152-9980-5117273aec44"
      },
      "outputs": [],
      "source": [
        "# !nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5bBZlqLTw7f"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# pip3 install --upgrade -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4PjBZQfY5oH"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBA_SAO_Y6rq"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLbLTB7NT-Iq"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import json\n",
        "import yaml\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "import torchvision\n",
        "from typing import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtAGUsIfUCxM"
      },
      "outputs": [],
      "source": [
        "from utils.util import *\n",
        "from config.data_config import DATASET\n",
        "from utils.dataset import DefaultDatasetSetupSSL\n",
        "from self_supervised.losses.contrastive_loss import (\n",
        "    ContrastiveLossEuclidean,\n",
        "    ContrastiveLossEmbedding,\n",
        "    SimCLR_Loss,\n",
        "    NegativeCosineSimilarity,\n",
        ")\n",
        "from self_supervised.losses.sym_neg_cos_sim_loss import SymNegCosineSimilarityLoss\n",
        "\n",
        "from models.modules.head import BYOLProjectionHead, BYOLPredictionHead\n",
        "from utils.scheduler import cosine_schedule\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from einops.layers.torch import Rearrange\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd3Ra8x_XG5D"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    \"dataset_name\": \"Model_II\",\n",
        "    \"save\": \"data\",\n",
        "    \"num_workers\": 8,\n",
        "    \"train_config_path\": \"self_supervised/config/resnet_byol.yaml\",\n",
        "    \"cuda\": True,\n",
        "    \"log_dir\": \"logger\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_BlwV27XHye"
      },
      "outputs": [],
      "source": [
        "batch_size = 3\n",
        "\n",
        "dataset_name = args[\"dataset_name\"]\n",
        "dataset_dir = args[\"save\"]\n",
        "use_cuda = args[\"cuda\"]\n",
        "num_workers = args[\"num_workers\"]\n",
        "train_config_path = args[\"train_config_path\"]\n",
        "log_dir_base = args[\"log_dir\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3neGI8FXH6S"
      },
      "outputs": [],
      "source": [
        "classes = DATASET[f\"{dataset_name}\"][\"classes\"]\n",
        "num_classes = len(classes)\n",
        "\n",
        "# Open the YAML file and load its contents\n",
        "with open(train_config_path, \"r\") as file:\n",
        "    train_config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk2BrahLXIQg"
      },
      "outputs": [],
      "source": [
        "learning_rate = train_config[\"optimizer_config\"][\"lr\"]\n",
        "margin = train_config[\"ssl\"][\"margin\"]\n",
        "num_channels = train_config[\"channels\"]\n",
        "temperature = train_config[\"ssl\"][\"temperature\"]\n",
        "network_type = train_config[\"network_type\"]\n",
        "image_size = train_config[\"image_size\"]\n",
        "optimizer_config = train_config[\"optimizer_config\"]\n",
        "\n",
        "backbone = train_config[\"backbone\"]\n",
        "\n",
        "make_directories([dataset_dir])\n",
        "seed_everything(seed=42)\n",
        "\n",
        "# logging\n",
        "current_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
        "log_dir = f\"{log_dir_base}/{current_time}\"\n",
        "init_logging_handler(log_dir_base, current_time)\n",
        "\n",
        "# dump config in logger\n",
        "with open(f\"{log_dir}/config.json\", \"w\") as fp:\n",
        "    json.dump(train_config, fp)\n",
        "\n",
        "# saving model path location\n",
        "model_path_pretrained = os.path.join(\n",
        "    f\"{log_dir}/checkpoint\",\n",
        "    f\"{network_type}_pretrained_{dataset_name}_{current_time}.pt\",\n",
        ")\n",
        "\n",
        "model_path_finetune = os.path.join(\n",
        "    f\"{log_dir}/checkpoint\",\n",
        "    f\"{network_type}_finetune_{dataset_name}_{current_time}.pt\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# paths\n",
        "finetuned_model_path = os.path.join(f\"{log_dir}/checkpoint\", f\"Resnet_dino_finetuned_{dataset_name}_{current_time}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "class DINOTransform:\n",
        "    \"\"\"Implements the global and local view augmentations for DINO [0].\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def get_transforms(self, \n",
        "                       global_crop_size: int = 224,\n",
        "                       global_crop_scale: Tuple[float, float] = (0.4, 1.0),\n",
        "                       local_crop_size: int = 96,\n",
        "                       local_crop_scale: Tuple[float, float] = (0.05, 0.4),):\n",
        "\n",
        "        # first global crop\n",
        "        global_transform_0 = A.Compose(\n",
        "        [\n",
        "            A.HorizontalFlip(p=0.25),\n",
        "            A.VerticalFlip(p=0.25),\n",
        "            A.Resize(global_crop_size, global_crop_size, p=1.0),\n",
        "            A.augmentations.GaussianBlur(),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "        # second global crop\n",
        "        global_transform_1 = A.Compose(\n",
        "        [\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.25),\n",
        "            A.Resize(global_crop_size, global_crop_size, p=1.0),\n",
        "            A.augmentations.GaussNoise(var_limit=(0.002, 0.005), p=0.3),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "        \n",
        "        # transformation for the local small crops\n",
        "        local_transform = A.Compose(\n",
        "        [\n",
        "            A.HorizontalFlip(p=0.25),\n",
        "            A.VerticalFlip(p=0.25),\n",
        "            A.Resize(local_crop_size, local_crop_size, p=1.0),\n",
        "            A.augmentations.GaussianBlur(),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "        return [global_transform_0, global_transform_1, local_transform]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjU0UUKVXIiA",
        "outputId": "9abb6f3f-bc71-4bf3-8426-1e0fb0db15fb"
      },
      "outputs": [],
      "source": [
        "from utils.dataset import visualize_samples_ssl, DeepLenseDatasetSSL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "home = os.getenv(\"HOME\")\n",
        "data_dir = home + \"/git/DeepLense/Transformers_Classification_DeepLense_Kartik_Sachdev/data\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_dataset(data_dir, transform, mode=\"train\", dataset_name=dataset_name):\n",
        "    assert mode in [\"train\", \"test\", \"val\"]\n",
        "\n",
        "    dataset = DeepLenseDatasetSSL(\n",
        "        destination_dir=data_dir,\n",
        "        dataset_name=dataset_name,\n",
        "        mode=mode,\n",
        "        transforms=transform,\n",
        "        download=True,\n",
        "        channels=1,\n",
        "    )\n",
        "\n",
        "    # get the number of samples in train and test set\n",
        "    print(f\"{mode} data: {len(dataset)}\")\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zLBymamXIx5",
        "outputId": "55e7933c-730f-4f97-c206-3905378761b3"
      },
      "outputs": [],
      "source": [
        "# trainset\n",
        "dino_transform = DINOTransform()\n",
        "train_transforms = dino_transform.get_transforms()\n",
        "train_dataset = get_dataset(data_dir, transform = train_transforms, mode=\"train\", dataset_name=dataset_name)\n",
        "visualize_samples_ssl(train_dataset, labels_map=classes, num_rows_inner=1, num_cols_inner=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxquTvHKUEN_",
        "outputId": "57116f52-9433-4ba5-dddb-e24585bacdeb"
      },
      "outputs": [],
      "source": [
        "# split in train and valid set\n",
        "split_ratio = 0.25  # 0.25\n",
        "valid_len = int(split_ratio * len(train_dataset))\n",
        "train_len = len(train_dataset) - valid_len\n",
        "\n",
        "train_dataset, val_set = random_split(train_dataset, [train_len, valid_len])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_set, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        ")\n",
        "\n",
        "# Load test dataset\n",
        "# testset = default_dataset_setup.get_dataset(mode=\"val\")\n",
        "# test_loader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# size check\n",
        "sample = next(iter(train_loader))\n",
        "print(\"num of classes: \", num_classes)\n",
        "print(sample[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightly.loss import DINOLoss\n",
        "from lightly.models.modules import DINOProjectionHead\n",
        "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
        "from lightly.transforms.dino_transform import DINOTransform\n",
        "from lightly.utils.scheduler import cosine_schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DINO(torch.nn.Module):\n",
        "    def __init__(self, backbone, input_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = backbone\n",
        "        self.backbone[0] = nn.Conv2d(\n",
        "            1, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
        "        )\n",
        "\n",
        "        self.student_backbone = self.backbone\n",
        "        self.student_head = DINOProjectionHead(\n",
        "            input_dim, 512, 64, 2048, freeze_last_layer=1\n",
        "        )\n",
        "        self.teacher_backbone = copy.deepcopy(self.backbone)\n",
        "        self.teacher_head = DINOProjectionHead(input_dim, 512, 64, 2048)\n",
        "        deactivate_requires_grad(self.teacher_backbone)\n",
        "        deactivate_requires_grad(self.teacher_head)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.student_backbone(x).flatten(start_dim=1)\n",
        "        z = self.student_head(y)\n",
        "        return z\n",
        "\n",
        "    def forward_teacher(self, x):\n",
        "        y = self.teacher_backbone(x).flatten(start_dim=1)\n",
        "        z = self.teacher_head(y)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUdzIhd3YZyQ",
        "outputId": "60a4dd4d-1152-4f4a-ba9f-e332eacfc8b2"
      },
      "outputs": [],
      "source": [
        "# Create pretrain model\n",
        "resnet = torchvision.models.resnet34()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "num_ftrs_dict = {\n",
        "    \"resnet18\": 512,\n",
        "    \"resnet34\": 512,\n",
        "    \"resnet50\": 2048,\n",
        "\n",
        "}\n",
        "\n",
        "model =  DINO(backbone, input_dim=num_ftrs_dict[\"resnet34\"])\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "summary(model, input_size=(2, 1, 224, 224), device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_pretrain = 1\n",
        "\n",
        "criterion_pretrain = DINOLoss(\n",
        "    output_dim=2048,\n",
        "    warmup_teacher_temp_epochs=5,\n",
        ")\n",
        "# move loss to correct device because it also contains parameters\n",
        "criterion_pretrain = criterion_pretrain.to(device)\n",
        "optimizer_pretrain = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Starting Training\")\n",
        "for epoch in range(epochs_pretrain):\n",
        "    total_loss = 0\n",
        "    best_loss = float(\"inf\")\n",
        "\n",
        "    momentum_val = cosine_schedule(epoch, epochs_pretrain, 0.996, 1)\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        views = batch[:3]\n",
        "        \n",
        "        update_momentum(model.student_backbone, model.teacher_backbone, m=momentum_val)\n",
        "        update_momentum(model.student_head, model.teacher_head, m=momentum_val)\n",
        "        views = [view.to(device) for view in views]\n",
        "        global_views = views[:2]\n",
        "        teacher_out = [model.forward_teacher(view) for view in global_views]\n",
        "        student_out = [model.forward(view) for view in views]\n",
        "        loss = criterion_pretrain(teacher_out, student_out, epoch=epoch)\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "        # We only cancel gradients of student head.\n",
        "        model.student_head.cancel_last_layer_gradients(current_epoch=epoch)\n",
        "        optimizer_pretrain.step()\n",
        "        optimizer_pretrain.zero_grad()\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{epochs_pretrain}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item()}\"\n",
        "            )\n",
        "\n",
        "    if total_loss < best_loss:\n",
        "        best_loss = total_loss\n",
        "        best_model = copy.deepcopy(model)\n",
        "        torch.save(best_model.state_dict(), model_path_pretrained)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FinetuneClassifier(nn.Module):\n",
        "    def __init__(self, backbone, head):\n",
        "        super(FinetuneClassifier, self).__init__()\n",
        "\n",
        "        deactivate_requires_grad(backbone)\n",
        "        self.backbone = backbone\n",
        "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "        self.rearrange = Rearrange(\"... () () -> ...\")\n",
        "        self.head = head\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.backbone(x)\n",
        "        z = self.pool(z)\n",
        "        z = self.rearrange(z)\n",
        "        z = self.head(z)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# del model\n",
        "# import gc\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()\n",
        "# print(torch.cuda.memory_allocated())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load model\n",
        "# model =  DINO(backbone, input_dim=num_ftrs_dict[\"resnet34\"])\n",
        "# model.load_state_dict(torch.load(model_path_pretrained))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "backbone = nn.Sequential(*list(model.backbone.children())[:-1])\n",
        "\n",
        "classification_head = nn.Sequential(\n",
        "    nn.Linear(num_ftrs_dict[\"resnet34\"], 512),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(512),\n",
        "    nn.Linear(512, num_classes),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "finetune_model = FinetuneClassifier(backbone, classification_head)\n",
        "finetune_model.to(device)\n",
        "\n",
        "summary(finetune_model, input_size=(1, 1, 224, 224), device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate = 3e-4\n",
        "weight_decay =  0.01\n",
        "\n",
        "finetune_optimizer = optim.AdamW(\n",
        "    finetune_model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        ")\n",
        "\n",
        "finetune_epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "finetune_criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def finetune(\n",
        "    epochs: int,\n",
        "    model: nn.Module,\n",
        "    device: Union[int, str],\n",
        "    train_loader: Any,\n",
        "    criterion: nn.Module,\n",
        "    optimizer: nn.Module,\n",
        "    saved_model_path: str,\n",
        "    valid_loader: Any,\n",
        "):\n",
        "    best_loss = float(\"inf\")\n",
        "    all_val_loss = []\n",
        "    all_val_accuracy = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader): # for batch_idx, batch in enumerate(train_loader):\n",
        "            img1 = batch[0].to(device)\n",
        "            label = batch[-1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(img1)\n",
        "\n",
        "            loss = criterion(output, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(\n",
        "                    f\"Epoch [{epoch}/{epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item()}\"\n",
        "                )\n",
        "\n",
        "        epoch_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "            torch.save(best_model.state_dict(), saved_model_path)\n",
        "            print(\"====== Model saved ======\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            print(\"====== Eval started ======\")\n",
        "            model.eval()\n",
        "            epoch_val_accuracy = 0\n",
        "            epoch_val_loss = 0\n",
        "            for batch_idx, batch in enumerate(train_loader): # for batch_idx, batch in enumerate(train_loader):\n",
        "                data = batch[0,1].to(device)\n",
        "                label = batch[-1].to(device)\n",
        "\n",
        "                val_output = model(data)\n",
        "                val_loss = criterion(val_output, label)\n",
        "\n",
        "                acc = (val_output.argmax(dim=1) == label).float().mean()\n",
        "                epoch_val_accuracy += acc\n",
        "                epoch_val_loss += val_loss\n",
        "\n",
        "            epoch_val_accuracy = epoch_val_accuracy / len(valid_loader)\n",
        "            epoch_val_loss = epoch_val_loss / len(valid_loader)\n",
        "            all_val_loss.append(epoch_val_loss)\n",
        "\n",
        "        all_val_accuracy.append(epoch_val_accuracy.item() * 100)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f} \\n\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "finetune(\n",
        "    finetune_epochs,\n",
        "    finetune_model,\n",
        "    device,\n",
        "    train_loader,\n",
        "    finetune_criterion,\n",
        "    finetune_optimizer,\n",
        "    finetuned_model_path,\n",
        "    valid_loader=val_loader,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vVWofjN-Sp6f"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
